{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "import ast, json, numpy as np\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from time import time\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import bert\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from laserembeddings import Laser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_sim(sents_1, sents_2):\n",
    "    sims = []\n",
    "    for s1, s2 in zip(sents_1, sents_2):\n",
    "        cs = cosine_similarity(s1.reshape(1, -1), s2.reshape(1, -1))\n",
    "        sims.append(cs)\n",
    "    sims = np.array(sims)\n",
    "    sims = sims.squeeze(1).squeeze(1)\n",
    "    print(sims.shape)\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>شخص ما يحمل لوح التزلج ليلا على الرصيف.</td>\n",
       "      <td>رجل جالس بمفرده يقرأ على طاولة مستديرة ، خارج ...</td>\n",
       "      <td>ar</td>\n",
       "      <td>ar</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>تتسابق النساء في سباق الدايتونا 500.</td>\n",
       "      <td>يتسابق بعض الرجال ضمن مسابقة التزلج.</td>\n",
       "      <td>ar</td>\n",
       "      <td>ar</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>تمشي النساء جنبا إلى جنب.</td>\n",
       "      <td>هناك فتيات يمشين متجاورات</td>\n",
       "      <td>ar</td>\n",
       "      <td>ar</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>يقفز الرجل ذو القميص الأخضر عاليا على العشب.</td>\n",
       "      <td>يمشي الرجل ذو القميص الأبيض على العشب الطويل م...</td>\n",
       "      <td>ar</td>\n",
       "      <td>ar</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>رجلان يجلسان على العشب ومعهما موز.</td>\n",
       "      <td>ثلاثة رجال يتسكعون عند فرشة بيع الفاكهة.</td>\n",
       "      <td>ar</td>\n",
       "      <td>ar</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             s1  \\\n",
       "0       شخص ما يحمل لوح التزلج ليلا على الرصيف.   \n",
       "1          تتسابق النساء في سباق الدايتونا 500.   \n",
       "2                     تمشي النساء جنبا إلى جنب.   \n",
       "3  يقفز الرجل ذو القميص الأخضر عاليا على العشب.   \n",
       "4            رجلان يجلسان على العشب ومعهما موز.   \n",
       "\n",
       "                                                  s2  l1  l2  score  \n",
       "0  رجل جالس بمفرده يقرأ على طاولة مستديرة ، خارج ...  ar  ar    0.8  \n",
       "1               يتسابق بعض الرجال ضمن مسابقة التزلج.  ar  ar    1.0  \n",
       "2                          هناك فتيات يمشين متجاورات  ar  ar    2.6  \n",
       "3  يمشي الرجل ذو القميص الأبيض على العشب الطويل م...  ar  ar    2.2  \n",
       "4           ثلاثة رجال يتسكعون عند فرشة بيع الفاكهة.  ar  ar    1.4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('2017_multilingual_eval_set.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_model(model_url, max_seq_length):\n",
    "  labse_layer = hub.KerasLayer(model_url, trainable=True)\n",
    "\n",
    "  # Define input.\n",
    "  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                         name=\"input_word_ids\")\n",
    "  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                     name=\"input_mask\")\n",
    "  segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                      name=\"segment_ids\")\n",
    "\n",
    "  # LaBSE layer.\n",
    "  pooled_output,  _ = labse_layer([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "  # The embedding is l2 normalized.\n",
    "  pooled_output = tf.keras.layers.Lambda(\n",
    "      lambda x: tf.nn.l2_normalize(x, axis=1))(pooled_output)\n",
    "\n",
    "  # Define model.\n",
    "  return tf.keras.Model(\n",
    "        inputs=[input_word_ids, input_mask, segment_ids],\n",
    "        outputs=pooled_output), labse_layer\n",
    "\n",
    "max_seq_length = 64\n",
    "labse_model, labse_layer = get_model(\n",
    "    model_url=\"https://tfhub.dev/google/LaBSE/1\", max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_file = labse_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = labse_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = bert.bert_tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "\n",
    "def create_input(input_strings, tokenizer, max_seq_length):\n",
    "\n",
    "  input_ids_all, input_mask_all, segment_ids_all = [], [], []\n",
    "  for input_string in input_strings:\n",
    "    # Tokenize input.\n",
    "    input_tokens = [\"[CLS]\"] + tokenizer.tokenize(input_string) + [\"[SEP]\"]\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(input_tokens)\n",
    "    sequence_length = min(len(input_ids), max_seq_length)\n",
    "\n",
    "    # Padding or truncation.\n",
    "    if len(input_ids) >= max_seq_length:\n",
    "      input_ids = input_ids[:max_seq_length]\n",
    "    else:\n",
    "      input_ids = input_ids + [0] * (max_seq_length - len(input_ids))\n",
    "\n",
    "    input_mask = [1] * sequence_length + [0] * (max_seq_length - sequence_length)\n",
    "\n",
    "    input_ids_all.append(input_ids)\n",
    "    input_mask_all.append(input_mask)\n",
    "    segment_ids_all.append([0] * max_seq_length)\n",
    "\n",
    "  return np.array(input_ids_all), np.array(input_mask_all), np.array(segment_ids_all)\n",
    "\n",
    "def encode(input_text):\n",
    "  input_ids, input_mask, segment_ids = create_input(\n",
    "    input_text, tokenizer, max_seq_length)\n",
    "  return labse_model([input_ids, input_mask, segment_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750, 768) (1750, 768)\n",
      "LaBSE Encoding time: 135.79\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "sents_1 = np.asarray(df.s1)\n",
    "sents_1 = encode(sents_1)\n",
    "sents_2 = np.asarray(df.s2)\n",
    "sents_2 = encode(sents_2)\n",
    "print(sents_1.shape, sents_2.shape)\n",
    "enc_time = time()-t0\n",
    "print(f'LaBSE Encoding time: {enc_time:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_1, sents_2 = np.array(sents_1), np.array(sents_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750,)\n"
     ]
    }
   ],
   "source": [
    "np.save('labse_sent_1.npy', sents_1)\n",
    "np.save('labse_sent_2.npy', sents_2)\n",
    "sims = get_cosine_sim(sents_1, sents_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labse_cosine_sim'] = sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>score</th>\n",
       "      <th>labse_cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>شخص ما يحمل لوح التزلج ليلا على الرصيف.</td>\n",
       "      <td>رجل جالس بمفرده يقرأ على طاولة مستديرة ، خارج ...</td>\n",
       "      <td>ar</td>\n",
       "      <td>ar</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.472780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>تتسابق النساء في سباق الدايتونا 500.</td>\n",
       "      <td>يتسابق بعض الرجال ضمن مسابقة التزلج.</td>\n",
       "      <td>ar</td>\n",
       "      <td>ar</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.436365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>تمشي النساء جنبا إلى جنب.</td>\n",
       "      <td>هناك فتيات يمشين متجاورات</td>\n",
       "      <td>ar</td>\n",
       "      <td>ar</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.523607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>يقفز الرجل ذو القميص الأخضر عاليا على العشب.</td>\n",
       "      <td>يمشي الرجل ذو القميص الأبيض على العشب الطويل م...</td>\n",
       "      <td>ar</td>\n",
       "      <td>ar</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.735741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>رجلان يجلسان على العشب ومعهما موز.</td>\n",
       "      <td>ثلاثة رجال يتسكعون عند فرشة بيع الفاكهة.</td>\n",
       "      <td>ar</td>\n",
       "      <td>ar</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.619040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             s1  \\\n",
       "0       شخص ما يحمل لوح التزلج ليلا على الرصيف.   \n",
       "1          تتسابق النساء في سباق الدايتونا 500.   \n",
       "2                     تمشي النساء جنبا إلى جنب.   \n",
       "3  يقفز الرجل ذو القميص الأخضر عاليا على العشب.   \n",
       "4            رجلان يجلسان على العشب ومعهما موز.   \n",
       "\n",
       "                                                  s2  l1  l2  score  \\\n",
       "0  رجل جالس بمفرده يقرأ على طاولة مستديرة ، خارج ...  ar  ar    0.8   \n",
       "1               يتسابق بعض الرجال ضمن مسابقة التزلج.  ar  ar    1.0   \n",
       "2                          هناك فتيات يمشين متجاورات  ar  ar    2.6   \n",
       "3  يمشي الرجل ذو القميص الأبيض على العشب الطويل م...  ar  ar    2.2   \n",
       "4           ثلاثة رجال يتسكعون عند فرشة بيع الفاكهة.  ar  ar    1.4   \n",
       "\n",
       "   labse_cosine_sim  \n",
       "0          0.472780  \n",
       "1          0.436365  \n",
       "2          0.523607  \n",
       "3          0.735741  \n",
       "4          0.619040  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.755018885185218"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.score.corr(df.labse_cosine_sim, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750, 512) (1750, 512)\n",
      "mUSE (tf-hub) encoding time: 4.1700\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n",
    "sents_1 = embed(df.s1)\n",
    "sents_2 = embed(df.s2)\n",
    "print(sents_1.shape, sents_2.shape)\n",
    "enc_time = time()-t0\n",
    "print(f'mUSE (tf-hub) encoding time: {enc_time:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_1, sents_2 = np.array(sents_1), np.array(sents_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('muse_sent_1.npy', sents_1)\n",
    "np.save('muse_sent_2.npy', sents_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750,)\n"
     ]
    }
   ],
   "source": [
    "sims = get_cosine_sim(sents_1, sents_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['muse_cosine_sim'] = sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7859717171575162"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.score.corr(df.muse_cosine_sim, method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception when trying to download https://sbert.net/models/xlm-roberta-base.zip. Response 404\n",
      "WARNING:root:SentenceTransformer-Model https://sbert.net/models/xlm-roberta-base.zip not found. Try to create it from scratch\n",
      "WARNING:root:Try to create Transformer Model xlm-roberta-base with mean pooling\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750, 768) (1750, 768)\n",
      "XLM RoBERTa (sBERT) encoding time: 32.83\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "sents_1 = model.encode(df.s1)\n",
    "sents_2 = model.encode(df.s2)\n",
    "print(sents_1.shape, sents_2.shape)\n",
    "enc_time = time()-t0\n",
    "print(f'XLM RoBERTa (sBERT) encoding time: {enc_time:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750,)\n"
     ]
    }
   ],
   "source": [
    "sims = get_cosine_sim(sents_1, sents_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['xlmr_cosine_sim'] = sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('average_word_embeddings_glove.6B.300d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750, 300) (1750, 300)\n",
      "Glove (sBERT) encoding time: 0.17\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "sents_1 = model.encode(df.s1)\n",
    "sents_2 = model.encode(df.s2)\n",
    "print(sents_1.shape, sents_2.shape)\n",
    "enc_time = time()-t0\n",
    "print(f'Glove (sBERT) encoding time: {enc_time:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('glove_avg_sent_1.npy', sents_1)\n",
    "np.save('glove_avg_sent_2.npy', sents_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750,)\n"
     ]
    }
   ],
   "source": [
    "sims = get_cosine_sim(sents_1, sents_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['glove_avg_sim'] = sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lang_pairs = [('ar','ar'),('ar','en'),('es','es'), ('es','en'), ('en','en'), ('tr','en')]\n",
    "# for p in lang_pairs:\n",
    "#     sdf = df[(df.l1 == p[0]) & (df.l2 == p[1])]\n",
    "#     print(p)\n",
    "#     print(f'labse: {sdf.score.corr(sdf.labse_cosine_sim)*100:.2f}, muse: {sdf.score.corr(sdf.muse_cosine_sim)*100:.2f},' \n",
    "#     f'xlmr: {sdf.score.corr(sdf.xlmr_cosine_sim)*100:.2f}, distil_muse: {sdf.score.corr(sdf.distilmuse_cosine_sim)*100:.2f},'\n",
    "#     f'xlmr_pt: {sdf.score.corr(sdf.xlmr_senttrans_sim)*100:.2f}, glove_avg: {sdf.score.corr(sdf.glove_avg_sim)*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lang_pairs = [('ar','ar'),('ar','en'),('es','es'), ('es','en'), ('en','en'), ('tr','en')]\n",
    "# for p in lang_pairs:\n",
    "#     sdf = df[(df.l1 == p[0]) & (df.l2 == p[1])]\n",
    "#     print(f'{sdf.score.corr(sdf.glove_avg_sim)*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser = Laser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1, l1 = df.s1, df.l1\n",
    "s2, l2 = df.s2, df.l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LASER (3rd party lib) encoding time: 11.208090543746948:.2f\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "sents_1 = laser.embed_sentences(list(s1), lang=list(l1))\n",
    "sents_2 = laser.embed_sentences(list(s2), lang=list(l2))\n",
    "enc_time = time()-t0\n",
    "print(f'LASER (3rd party lib) encoding time: {enc_time:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1750, 1024), (1750, 1024))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_1.shape, sents_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('laser_sent_1.npy', sents_1)\n",
    "np.save('laser_sent_2.npy', sents_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750,)\n"
     ]
    }
   ],
   "source": [
    "sims = get_cosine_sim(sents_1, sents_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>score</th>\n",
       "      <th>labse_cosine_sim</th>\n",
       "      <th>muse_cosine_sim</th>\n",
       "      <th>xlmr_cosine_sim</th>\n",
       "      <th>glove_avg_sim</th>\n",
       "      <th>laser_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>A coach smiles at a player.</td>\n",
       "      <td>Bir koç, oyuncularıyla birlikte kenarda durur.</td>\n",
       "      <td>tr</td>\n",
       "      <td>en</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.567708</td>\n",
       "      <td>0.383282</td>\n",
       "      <td>0.992406</td>\n",
       "      <td>-0.171986</td>\n",
       "      <td>0.664306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>Six women wearing black jackets and bright red...</td>\n",
       "      <td>Sarı gömlekli üç kadın kameraya gülümsüyor.</td>\n",
       "      <td>tr</td>\n",
       "      <td>en</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.725851</td>\n",
       "      <td>0.547926</td>\n",
       "      <td>0.995444</td>\n",
       "      <td>-0.110193</td>\n",
       "      <td>0.727363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>There are 70 participants on each team on the ...</td>\n",
       "      <td>Sahada iki takım var.</td>\n",
       "      <td>tr</td>\n",
       "      <td>en</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.637072</td>\n",
       "      <td>0.345799</td>\n",
       "      <td>0.994337</td>\n",
       "      <td>-0.232244</td>\n",
       "      <td>0.659134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>A large family poses for a photo.</td>\n",
       "      <td>Fotoğraf çeken bir aile var</td>\n",
       "      <td>tr</td>\n",
       "      <td>en</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.613873</td>\n",
       "      <td>0.595023</td>\n",
       "      <td>0.995790</td>\n",
       "      <td>-0.181362</td>\n",
       "      <td>0.738873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>A girl is inspecting a machine.</td>\n",
       "      <td>Bir kadın bir makineyle çalışıyor.</td>\n",
       "      <td>tr</td>\n",
       "      <td>en</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.661635</td>\n",
       "      <td>0.580531</td>\n",
       "      <td>0.995913</td>\n",
       "      <td>-0.071709</td>\n",
       "      <td>0.833054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     s1  \\\n",
       "1745                        A coach smiles at a player.   \n",
       "1746  Six women wearing black jackets and bright red...   \n",
       "1747  There are 70 participants on each team on the ...   \n",
       "1748                  A large family poses for a photo.   \n",
       "1749                    A girl is inspecting a machine.   \n",
       "\n",
       "                                                  s2  l1  l2  score  \\\n",
       "1745  Bir koç, oyuncularıyla birlikte kenarda durur.  tr  en    2.4   \n",
       "1746     Sarı gömlekli üç kadın kameraya gülümsüyor.  tr  en    1.6   \n",
       "1747                           Sahada iki takım var.  tr  en    2.8   \n",
       "1748                     Fotoğraf çeken bir aile var  tr  en    4.0   \n",
       "1749              Bir kadın bir makineyle çalışıyor.  tr  en    3.4   \n",
       "\n",
       "      labse_cosine_sim  muse_cosine_sim  xlmr_cosine_sim  glove_avg_sim  \\\n",
       "1745          0.567708         0.383282         0.992406      -0.171986   \n",
       "1746          0.725851         0.547926         0.995444      -0.110193   \n",
       "1747          0.637072         0.345799         0.994337      -0.232244   \n",
       "1748          0.613873         0.595023         0.995790      -0.181362   \n",
       "1749          0.661635         0.580531         0.995913      -0.071709   \n",
       "\n",
       "      laser_sim  \n",
       "1745   0.664306  \n",
       "1746   0.727363  \n",
       "1747   0.659134  \n",
       "1748   0.738873  \n",
       "1749   0.833054  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['laser_sim'] = sims\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.33\n",
      "65.56\n",
      "79.73\n",
      "70.52\n",
      "77.13\n",
      "72.14\n"
     ]
    }
   ],
   "source": [
    "lang_pairs = [('ar','ar'),('ar','en'),('es','es'), ('es','en'), ('en','en'), ('tr','en')]\n",
    "for p in lang_pairs:\n",
    "    sdf = df[(df.l1 == p[0]) & (df.l2 == p[1])]\n",
    "    print(f'{sdf.score.corr(sdf.laser_sim)*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labse_cosine_sim, 75.50\n",
      "muse_cosine_sim, 78.60\n",
      "xlmr_cosine_sim, 24.04\n",
      "glove_avg_sim, 3.01\n",
      "laser_sim, 73.55\n"
     ]
    }
   ],
   "source": [
    "for c in df.columns:\n",
    "    if 'sim' not in c:\n",
    "        continue\n",
    "    else:\n",
    "        print(f'{c}, {df.score.corr(df[c], method=\"spearman\")*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distiluse-base-multilingual-cased (sBERT) encoding time: 21.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:21<01:05, 21.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750,)\n",
      "distilbert-multilingual-nli-stsb-quora-ranking (sBERT) encoding time: 21.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:43<00:43, 21.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750,)\n",
      "xlm-r-100langs-bert-base-nli-mean-tokens (sBERT) encoding time: 47.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [01:32<00:29, 29.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750,)\n",
      "xlm-r-100langs-bert-base-nli-stsb-mean-tokens (sBERT) encoding time: 48.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:20<00:00, 35.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_names = ['distiluse-base-multilingual-cased', \n",
    "               'distilbert-multilingual-nli-stsb-quora-ranking',\n",
    "               'xlm-r-100langs-bert-base-nli-mean-tokens',\n",
    "               'xlm-r-100langs-bert-base-nli-stsb-mean-tokens']\n",
    "for mname in tqdm(model_names):\n",
    "    t0 = time()\n",
    "    model = SentenceTransformer(mname)\n",
    "    sents_1 = model.encode(df.s1)\n",
    "    sents_2 = model.encode(df.s2)\n",
    "    enc_time = time() - t0\n",
    "    enc_time = time()-t0\n",
    "    print(f'{mname} (sBERT) encoding time: {enc_time:.2f}')\n",
    "    sims = get_cosine_sim(sents_1, sents_2)\n",
    "    df[mname+'_sim'] = sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labse_cosine_sim 69.09 74.51 80.81 68.69 79.37 72.02 75.50\n",
      "muse_cosine_sim 71.81 74.71 84.01 71.64 85.23 71.74 78.60\n",
      "xlmr_cosine_sim 25.49 15.71 49.58 44.46 52.17 12.07 24.04\n",
      "glove_avg_sim 8.12 6.89 49.84 6.39 77.93 2.60 3.01\n",
      "laser_sim 68.84 66.53 79.69 69.09 77.62 72.19 73.55\n",
      "distiluse-base-multilingual-cased_sim 75.86 77.55 85.33 69.38 85.37 75.51 80.70\n",
      "distilbert-multilingual-nli-stsb-quora-ranking_sim 70.77 70.97 78.59 71.04 79.00 62.74 75.72\n",
      "xlm-r-100langs-bert-base-nli-mean-tokens_sim 75.41 72.52 77.11 74.51 78.20 70.26 77.77\n",
      "xlm-r-100langs-bert-base-nli-stsb-mean-tokens_sim 78.66 77.39 83.13 75.27 82.40 75.89 81.44\n"
     ]
    }
   ],
   "source": [
    "cols = [c for c in df.columns if 'sim' in c]\n",
    "\n",
    "for c in cols:\n",
    "    lang_pairs = [('ar','ar'),('ar','en'),('es','es'), ('es','en'), ('en','en'), ('tr','en')]\n",
    "    res = []\n",
    "    for p in lang_pairs:\n",
    "        sdf = df[(df.l1 == p[0]) & (df.l2 == p[1])]\n",
    "        scc = f'{sdf.score.corr(sdf[c], method=\"spearman\")*100:.2f}'\n",
    "        res.append(scc)\n",
    "    overall_scc = f'{df.score.corr(df[c], method=\"spearman\")*100:.2f}'\n",
    "    res.append(overall_scc)\n",
    "    print(f'{c} {\" \".join(res)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
